{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd088212c6b79be9b544bafe6735d74fe8c206b1cc2a4f62e98b323686df1ed5be2",
   "display_name": "Python 3.7.7 64-bit ('dataScience': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Time Series Forcast - sunspots"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "```\n",
    "Step 0. Library Import\n",
    "Step 1. Load Dataset\n",
    "Step 2. Data Preprocessing\n",
    "Step 3. Modeling\n",
    "Step 4. Model Compile\n",
    "Step 5. Model Checkpoint\n",
    "Step 6. Model Fit\n",
    "Step 7. Model Evaluate & Save\n",
    "Step 8. Model Reload\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Step 0. Library Import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import urllib\n",
    "import numpy as np \n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense, LSTM, Lambda, Conv1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import Huber"
   ]
  },
  {
   "source": [
    "## Step 1. Load Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('./data/sunspots.csv', <http.client.HTTPMessage at 0x7fb0853b8f90>)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "url = 'https://storage.googleapis.com/download.tensorflow.org/data/Sunspots.csv'\n",
    "data_path = './data/sunspots.csv'\n",
    "\n",
    "urllib.request.urlretrieve(url, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunspots = []\n",
    "time_step = []\n",
    "\n",
    "with open(data_path) as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    next(reader) # first line skip\n",
    "    for row in reader:\n",
    "        sunspots.append(float(row[2]))\n",
    "        time_step.append(int(row[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sunspot :  96.7\ntime step : 0\n-----------------------\nsunspot :  104.3\ntime step : 1\n-----------------------\nsunspot :  116.7\ntime step : 2\n-----------------------\nsunspot :  92.8\ntime step : 3\n-----------------------\nsunspot :  141.7\ntime step : 4\n-----------------------\nsunspot :  139.2\ntime step : 5\n-----------------------\nsunspot :  158.0\ntime step : 6\n-----------------------\nsunspot :  110.5\ntime step : 7\n-----------------------\nsunspot :  126.5\ntime step : 8\n-----------------------\nsunspot :  125.8\ntime step : 9\n-----------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('sunspot : ', sunspots[i])\n",
    "    print('time step :', time_step[i])\n",
    "    print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "type of -sunspots- :  <class 'list'>\ntype of -time_step- :  <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print('type of -sunspots- : ', type(sunspots))\n",
    "print('type of -time_step- : ', type(time_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunspots = np.array(sunspots)\n",
    "time_step = np.array(time_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "type of -sunspots- :  <class 'numpy.ndarray'>\nsize of -sunspots- :  (3235,)\ntype of -time_step- :  <class 'numpy.ndarray'>\nsize of -time_step- :  (3235,)\n"
     ]
    }
   ],
   "source": [
    "print('type of -sunspots- : ', type(sunspots))\n",
    "print('size of -sunspots- : ', sunspots.shape)\n",
    "print('type of -time_step- : ', type(time_step))\n",
    "print('size of -time_step- : ', time_step.shape)"
   ]
  },
  {
   "source": [
    "## Step 2. Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_time = 3000\n",
    "\n",
    "time_train = time_step[:split_time]\n",
    "time_valid = time_step[split_time:]\n",
    "\n",
    "x_train = sunspots[:split_time]\n",
    "x_valid = sunspots[split_time:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 30\n",
    "batch_size = 32\n",
    "shuffle_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    series = tf.expand_dims(series, axis=1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size+1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w : w.batch(window_size+1))\n",
    "    ds = ds.shuffle(shuffle_buffer)\n",
    "    ds = ds.map(lambda w : (w[:-1], w[1:]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = windowed_dataset(\n",
    "    x_train,\n",
    "    window_size = window_size,\n",
    "    batch_size = batch_size,\n",
    "    shuffle_buffer = shuffle_size\n",
    ")\n",
    "\n",
    "valid_set = windowed_dataset(\n",
    "    x_valid,\n",
    "    window_size = window_size,\n",
    "    batch_size = batch_size,\n",
    "    shuffle_buffer = shuffle_size\n",
    ")"
   ]
  },
  {
   "source": [
    "## Step 3. Modeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.layers.Conv1D(60, kernel_size=5, padding='causal', activation='relu', input_shape=[None, 1]),\n",
    "    tf.keras.layers.LSTM(60, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(60, return_sequences=True),\n",
    "    tf.keras.layers.Dense(30, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1),\n",
    "    tf.keras.layers.Lambda(lambda x : x * 400)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d (Conv1D)              (None, None, 60)          360       \n_________________________________________________________________\nlstm (LSTM)                  (None, None, 60)          29040     \n_________________________________________________________________\nlstm_1 (LSTM)                (None, None, 60)          29040     \n_________________________________________________________________\ndense (Dense)                (None, None, 30)          1830      \n_________________________________________________________________\ndense_1 (Dense)              (None, None, 10)          310       \n_________________________________________________________________\ndense_2 (Dense)              (None, None, 1)           11        \n_________________________________________________________________\nlambda (Lambda)              (None, None, 1)           0         \n=================================================================\nTotal params: 60,591\nTrainable params: 60,591\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "source": [
    "## Step 4. Model Compile"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(lr=1e-5, momentum=0.9)\n",
    "loss = Huber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=['mae']\n",
    ")"
   ]
  },
  {
   "source": [
    "## Step 5. Model Checkpoint"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'my_checkpoint.ckpt'\n",
    "cp = ModelCheckpoint(\n",
    "    filepath,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    monitor='val_mae',\n",
    "    verbose=1\n",
    "    )"
   ]
  },
  {
   "source": [
    "## Step 6. Model Fit"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "     92/Unknown - 2s 23ms/step - loss: 42.3937 - mae: 42.8905\n",
      "Epoch 00001: val_mae improved from inf to 20.35585, saving model to my_checkpoint.ckpt\n",
      "93/93 [==============================] - 3s 32ms/step - loss: 42.2213 - mae: 42.7182 - val_loss: 19.8602 - val_mae: 20.3558\n",
      "Epoch 2/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 21.9800 - mae: 22.4733\n",
      "Epoch 00002: val_mae improved from 20.35585 to 18.27837, saving model to my_checkpoint.ckpt\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 21.9348 - mae: 22.4282 - val_loss: 17.7844 - val_mae: 18.2784\n",
      "Epoch 3/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 19.6112 - mae: 20.1041\n",
      "Epoch 00003: val_mae improved from 18.27837 to 16.02726, saving model to my_checkpoint.ckpt\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 19.6225 - mae: 20.1154 - val_loss: 15.5362 - val_mae: 16.0273\n",
      "Epoch 4/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 18.7598 - mae: 19.2522\n",
      "Epoch 00004: val_mae improved from 16.02726 to 15.97786, saving model to my_checkpoint.ckpt\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 18.7642 - mae: 19.2567 - val_loss: 15.4864 - val_mae: 15.9779\n",
      "Epoch 5/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 18.6354 - mae: 19.1279\n",
      "Epoch 00005: val_mae improved from 15.97786 to 15.51149, saving model to my_checkpoint.ckpt\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 18.6443 - mae: 19.1367 - val_loss: 15.0200 - val_mae: 15.5115\n",
      "Epoch 6/30\n",
      "93/93 [==============================] - ETA: 0s - loss: 18.1209 - mae: 18.6127\n",
      "Epoch 00006: val_mae improved from 15.51149 to 15.25144, saving model to my_checkpoint.ckpt\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 18.1209 - mae: 18.6127 - val_loss: 14.7599 - val_mae: 15.2514\n",
      "Epoch 7/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 18.5959 - mae: 19.0880\n",
      "Epoch 00007: val_mae did not improve from 15.25144\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 18.6032 - mae: 19.0954 - val_loss: 18.2805 - val_mae: 18.7731\n",
      "Epoch 8/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 18.0648 - mae: 18.5569\n",
      "Epoch 00008: val_mae did not improve from 15.25144\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 18.0725 - mae: 18.5646 - val_loss: 14.9478 - val_mae: 15.4409\n",
      "Epoch 9/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 18.1227 - mae: 18.6143\n",
      "Epoch 00009: val_mae did not improve from 15.25144\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 18.0726 - mae: 18.5642 - val_loss: 14.8586 - val_mae: 15.3506\n",
      "Epoch 10/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 17.8093 - mae: 18.3008\n",
      "Epoch 00010: val_mae improved from 15.25144 to 14.86233, saving model to my_checkpoint.ckpt\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.8295 - mae: 18.3211 - val_loss: 14.3718 - val_mae: 14.8623\n",
      "Epoch 11/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 18.0843 - mae: 18.5758\n",
      "Epoch 00011: val_mae improved from 14.86233 to 14.84520, saving model to my_checkpoint.ckpt\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 18.0550 - mae: 18.5465 - val_loss: 14.3545 - val_mae: 14.8452\n",
      "Epoch 12/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 17.6615 - mae: 18.1530\n",
      "Epoch 00012: val_mae did not improve from 14.84520\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.6913 - mae: 18.1828 - val_loss: 15.5799 - val_mae: 16.0712\n",
      "Epoch 13/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 17.9967 - mae: 18.4884\n",
      "Epoch 00013: val_mae improved from 14.84520 to 14.49098, saving model to my_checkpoint.ckpt\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.9925 - mae: 18.4843 - val_loss: 13.9991 - val_mae: 14.4910\n",
      "Epoch 14/30\n",
      "93/93 [==============================] - ETA: 0s - loss: 17.4841 - mae: 17.9756\n",
      "Epoch 00014: val_mae did not improve from 14.49098\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.4841 - mae: 17.9756 - val_loss: 15.5568 - val_mae: 16.0487\n",
      "Epoch 15/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 17.6383 - mae: 18.1294\n",
      "Epoch 00015: val_mae did not improve from 14.49098\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.6305 - mae: 18.1216 - val_loss: 14.2477 - val_mae: 14.7372\n",
      "Epoch 16/30\n",
      "93/93 [==============================] - ETA: 0s - loss: 17.3817 - mae: 17.8732\n",
      "Epoch 00016: val_mae did not improve from 14.49098\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.3817 - mae: 17.8732 - val_loss: 14.0772 - val_mae: 14.5682\n",
      "Epoch 17/30\n",
      "93/93 [==============================] - ETA: 0s - loss: 17.2804 - mae: 17.7712\n",
      "Epoch 00017: val_mae did not improve from 14.49098\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.2804 - mae: 17.7712 - val_loss: 14.0613 - val_mae: 14.5532\n",
      "Epoch 18/30\n",
      "93/93 [==============================] - ETA: 0s - loss: 17.5651 - mae: 18.0562\n",
      "Epoch 00018: val_mae did not improve from 14.49098\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.5651 - mae: 18.0562 - val_loss: 14.7300 - val_mae: 15.2211\n",
      "Epoch 19/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 17.5336 - mae: 18.0246\n",
      "Epoch 00019: val_mae did not improve from 14.49098\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.5391 - mae: 18.0302 - val_loss: 16.5333 - val_mae: 17.0249\n",
      "Epoch 20/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 17.4072 - mae: 17.8981\n",
      "Epoch 00020: val_mae did not improve from 14.49098\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.4276 - mae: 17.9185 - val_loss: 14.8603 - val_mae: 15.3514\n",
      "Epoch 21/30\n",
      "93/93 [==============================] - ETA: 0s - loss: 17.5152 - mae: 18.0063\n",
      "Epoch 00021: val_mae did not improve from 14.49098\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.5152 - mae: 18.0063 - val_loss: 14.0248 - val_mae: 14.5147\n",
      "Epoch 22/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 17.3582 - mae: 17.8494\n",
      "Epoch 00022: val_mae did not improve from 14.49098\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.3556 - mae: 17.8468 - val_loss: 15.2254 - val_mae: 15.7157\n",
      "Epoch 23/30\n",
      "93/93 [==============================] - ETA: 0s - loss: 17.2425 - mae: 17.7335\n",
      "Epoch 00023: val_mae did not improve from 14.49098\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.2425 - mae: 17.7335 - val_loss: 14.0808 - val_mae: 14.5696\n",
      "Epoch 24/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 17.2498 - mae: 17.7403\n",
      "Epoch 00024: val_mae improved from 14.49098 to 14.42068, saving model to my_checkpoint.ckpt\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.2495 - mae: 17.7401 - val_loss: 13.9309 - val_mae: 14.4207\n",
      "Epoch 25/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 17.1682 - mae: 17.6589\n",
      "Epoch 00025: val_mae improved from 14.42068 to 14.38014, saving model to my_checkpoint.ckpt\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.1586 - mae: 17.6494 - val_loss: 13.8908 - val_mae: 14.3801\n",
      "Epoch 26/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 17.2073 - mae: 17.6984\n",
      "Epoch 00026: val_mae did not improve from 14.38014\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.2173 - mae: 17.7083 - val_loss: 14.4642 - val_mae: 14.9533\n",
      "Epoch 27/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 17.2314 - mae: 17.7226\n",
      "Epoch 00027: val_mae did not improve from 14.38014\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.1942 - mae: 17.6854 - val_loss: 14.0705 - val_mae: 14.5614\n",
      "Epoch 28/30\n",
      "91/93 [============================>.] - ETA: 0s - loss: 17.1265 - mae: 17.6174\n",
      "Epoch 00028: val_mae did not improve from 14.38014\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 17.1361 - mae: 17.6270 - val_loss: 13.8945 - val_mae: 14.3820\n",
      "Epoch 29/30\n",
      "93/93 [==============================] - ETA: 0s - loss: 17.0736 - mae: 17.5639\n",
      "Epoch 00029: val_mae did not improve from 14.38014\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 17.0736 - mae: 17.5639 - val_loss: 14.0616 - val_mae: 14.5517\n",
      "Epoch 30/30\n",
      "93/93 [==============================] - ETA: 0s - loss: 17.0454 - mae: 17.5363\n",
      "Epoch 00030: val_mae did not improve from 14.38014\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 17.0454 - mae: 17.5363 - val_loss: 14.0193 - val_mae: 14.5110\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb06c5136d0>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_set,\n",
    "    validation_data = valid_set,\n",
    "    epochs=epochs,\n",
    "    callbacks=[cp]\n",
    ")"
   ]
  },
  {
   "source": [
    "## Step 7. Model Evaluate & Save"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fb06e219ed0>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "model.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7/7 [==============================] - 0s 5ms/step - loss: 13.8908 - mae: 14.3801\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[13.890848159790039, 14.380138397216797]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "model.evaluate(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/sunspot__val_mae_13.90.h5')"
   ]
  },
  {
   "source": [
    "## Step 8. Model Reload"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = tf.keras.models.load_model('./model/sunspot__val_mae_13.90.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d (Conv1D)              (None, None, 60)          360       \n_________________________________________________________________\nlstm (LSTM)                  (None, None, 60)          29040     \n_________________________________________________________________\nlstm_1 (LSTM)                (None, None, 60)          29040     \n_________________________________________________________________\ndense (Dense)                (None, None, 30)          1830      \n_________________________________________________________________\ndense_1 (Dense)              (None, None, 10)          310       \n_________________________________________________________________\ndense_2 (Dense)              (None, None, 1)           11        \n_________________________________________________________________\nlambda (Lambda)              (None, None, 1)           0         \n=================================================================\nTotal params: 60,591\nTrainable params: 60,591\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mymodel.summary()"
   ]
  }
 ]
}