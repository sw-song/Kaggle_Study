# TIA(Today I Analyzed) - Kaggle Study
### Rule :
* 직접 분석한 데이터만 순번을 올린다.
* 분석 후 학습(Clone)할 Kernel이 있다면 순번을 올리지 않고, '**+**'표시한다.
* 데이터를 직접 분석하기 전에 다른 Kernel을 Clone하지 않는다.

---
**[1. HR Analytics : Job Change of Data Scientists - Predict who will move to a new job](https://github.com/sw-song/TIA/blob/main/job_change_of_data_scientists/HR_Analytics.ipynb)**
```
Step 1. Library Import
Step 2. Data Read
Step 3. EDA
Step 3-1. EDA - Visualization | Numerical Columns
Step 3-2. EDA - Visualization | Categorical Columns
Step 4. Train & Validation Set 분리
Step 5. Model 생성 및 학습
Step 6. Validation data Accuracy 측정
```

**[1+. HR Analytics : Job Change of Data Scientists - Clone Project(Kaggle, HR Analytics for begineer - S P Rakshith)](https://github.com/sw-song/TIA/blob/main/job_change_of_data_scientists/Clone__HR_Analytics_for_beginners.ipynb)**
```
Step 1. Importing the necessery libraries
Step 2. Importing the Data, head(), info()
Step 3. Checking the total number of Null Data - insa()
Step 4. Visualize the Categorical Data
Step 5. Modeling & Prediction
Step 6. Evaluation - Confusion Matrix
```

**[1+. HR Analytics : Job Change of Data Scientists - Clone Project(Kaggle, Predict who will move to a new job - Siti Khotijah)](https://github.com/sw-song/TIA/blob/main/job_change_of_data_scientists/Clone__Predict_who_will_move_to_a_new_job.ipynb)**
```
Step 1. Import data
Step 2. Visualization
Step 3. Check missing Value and Replace Them with average of columns
Step 4. Type Tansfer - Categorical to Numerical
Step 5. Modeling & Prediction
Step 6. Evaluation - AUC
```
---

**[2. Youtube trend Analysis : Check Daily statistics for trending Youtube videos](https://github.com/sw-song/TIA/blob/main/Youtube_trend_KR/youtube_trend_analysis.ipynb)**
```
Step 1. Data Load & EDA
Step 2. Correlation Check - Heatmap
(+Time Series)
Step 3. Visualization - Numerical Columns
Step 4. Visualization - WordCloud
Step 5. Machine Learning Modeling(Keras)
```
---

**[3. NLP Getting Started Tutorial - Clone Project(Kaggle, NLP Getting Started Tutorial, Phill Culliton)](https://github.com/sw-song/TIA/blob/main/NLP_with_Disaster_Tweets/Clone_NLP_Getting_Started_Tutorial.ipynb)**
```
Step 1. Data Load & EDA
Step 2. Text -> Vectorization(One Hot Encoding)
Step 3. Cross Validation Check
Step 4. Modeling
Step 5. Save / Submission(kaggle)
```
---

**[4. Telecom Users Dataset Analysis - Predict User's Next Action with Logistic Regression](https://github.com/sw-song/TIA/blob/main/Telecom_users_analysis/quick-start-eda-to-machine-learning-logistic.ipynb)**
```
Step 1. Data Load & EDA
Step 2. Data Preprocessing
Step 3. Dataset Split(Train : Test = 0.8 : 0.2)
Step 4. Modeling : Logistic Regression
```

**[4+. Telecom Users Dataset Analysis - Clone Project(Kaggle, EDA and Building models for predicting outflow](https://github.com/sw-song/TIA/blob/main/Telecom_users_analysis/Clone_EDA_and_Building_models_for_predicting_outflow.ipynb)**
```
Step 1. Data Description
Step 2. Dependency research and formulation of hypothesis
Step 3. Building models to predict outflow
```
---

**[5. Heart Attack Analysis and Prediction - Binary Classification with Logistic Regression](https://github.com/sw-song/TIA/blob/main/Heart_Attack_Analysis_and_Prediction/quick-start-Binary_Classification_with_Logistic_Regression.ipynb)**
```
Step 1. Data Description
Step 2. EDA
Step 3. Correlation Check
Step 4. Test Data Split and Standard Scaling (Test size = 0.3)
Step 5. Modeling and Prediction
```

**[5+. Heart Attack Analysis and Prediction - Clone Project(Kaggle, Heart Attack Prediction_95.4% accuracy)](https://github.com/sw-song/TIA/blob/main/Heart_Attack_Analysis_and_Prediction/Clone_Heart_attack_prediction.ipynb)**
```
Step 1. Data Description - missingno
Step 2. EDA - pandas_profiling
Step 3. Data preprocessing - remove Outlier, upsampling
Step 4. modeling / prediction / evaluation
Step 5. check feature importance
```
---

**[6. Bankruptcy Prediction with KNN - Acc 97%](https://github.com/sw-song/TIA/blob/main/Company_Bankruptcy_Prediction/Bankruptcy_Prediction_with_KNN.ipynb)**
```
Step 1. Data Description
Step 2. Data Preprocessing - MinMaxScaling
Step 3. Machine Learning Modeling & Prediction
```

**[6+. Bankruptcy_Prediction - Clone Project(Simple, yet, Powerful Bankrupt Prediction Model)](https://github.com/sw-song/TIA/blob/main/Company_Bankruptcy_Prediction/Clone_Powerful_Bankrupt_Prediction.ipynb)**
```
Step 1. Data Loading and Data Cleaning
Step 2. Model Based Feature Selection
Step 3. Descriptive Analysis
Step 4. Data Analysis
Step 5. Predicting bankruptcy
Step 6. Conclusions
```
---
**[7. Anomaly Detection with XGB Classifier(base model Accuracy 79%) - Facebook Recruiting IV: Human or Robot?](https://github.com/sw-song/TIA/blob/main/Classification_Human_or_Robot/Anomaly_Detection_with_XGBClassifier.ipynb)**
```
Step 1. Data load & EDA
Step 2. Preprocessing - replace all values with count number
Step 3. Preprocessing - Upsampling
Step 4. Train / Valid Set Split
Step 5. Modeling
Step 6. Prediction
```

---
**[8. Stroke Prediction with EASY Ensemble - Acc 90%(Random Forest Base model - 90%, Gradient Boosting Tuning Model)](https://github.com/sw-song/TIA/blob/main/Stroke_Prediction/stroke_prediction.ipynb)**
```
Step 1. Data Load & EDA
Step 2. Feature Engineering
     2-a. Binary Features
     2-b. Continuous Features
     2-c. Categorical Features
Step 3. Train / Test set Split & Upsampling
Step 4. Modeling & Prediction
```

**[8+. Stroke Prediction - Clone Project(Stroke Prediction Beginner's Guide)](https://github.com/sw-song/TIA/blob/main/Stroke_Prediction/Clone_stroke_prediction.ipynb)**
```
Step 1. Importing the necessary libraries
Step 2. Importing the Data using Pandas read_csv(). And calling head() and info() on the DataFrame
Step 3. Preprocessing Data before Exploratory Data Analysis
Step 4. Exploratory Data Analysis on Stroke Prediction Data
Step 5. Preparing the Data for Prediction
Step 6. Creating a Model for Stroke Prediction
```


