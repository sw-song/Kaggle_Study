# TIA(Today I Analyzed) - Kaggle Study
### Rule :
* 직접 분석한 데이터만 순번을 올린다.
* 분석 후 학습(Clone)할 Kernel이 있다면 순번을 올리지 않고, '**+**'표시한다.
* 데이터를 직접 분석하기 전에 다른 Kernel을 Clone하지 않는다.

---
<<<<<<< HEAD
**[1. HR Analytics : Job Change of Data Scientists - Predict who will move to a new job](https://github.com/sw-song/TIA/blob/main/1_HR_Analytics/HR_Analytics.ipynb)**
=======
**[1. HR Analytics : Job Change of Data Scientists - Predict who will move to a new job](https://github.com/sw-song/TIA/blob/main/job_change_of_data_scientists/HR_Analytics.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Library Import
Step 2. Data Read
Step 3. EDA
Step 3-1. EDA - Visualization | Numerical Columns
Step 3-2. EDA - Visualization | Categorical Columns
Step 4. Train & Validation Set 분리
Step 5. Model 생성 및 학습
Step 6. Validation data Accuracy 측정
```

<<<<<<< HEAD
**[1+. HR Analytics : Job Change of Data Scientists - Clone Project(Kaggle, HR Analytics for begineer - S P Rakshith)](https://github.com/sw-song/TIA/blob/main/1_HR_Analytics/Clone__HR_Analytics_for_beginners.ipynb)**
=======
**[1+. HR Analytics : Job Change of Data Scientists - Clone Project(Kaggle, HR Analytics for begineer - S P Rakshith)](https://github.com/sw-song/TIA/blob/main/job_change_of_data_scientists/Clone__HR_Analytics_for_beginners.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Importing the necessery libraries
Step 2. Importing the Data, head(), info()
Step 3. Checking the total number of Null Data - insa()
Step 4. Visualize the Categorical Data
Step 5. Modeling & Prediction
Step 6. Evaluation - Confusion Matrix
```

<<<<<<< HEAD
**[1+. HR Analytics : Job Change of Data Scientists - Clone Project(Kaggle, Predict who will move to a new job - Siti Khotijah)](https://github.com/sw-song/TIA/blob/main/1_HR_Analytics/Clone__Predict_who_will_move_to_a_new_job.ipynb)**
=======
**[1+. HR Analytics : Job Change of Data Scientists - Clone Project(Kaggle, Predict who will move to a new job - Siti Khotijah)](https://github.com/sw-song/TIA/blob/main/job_change_of_data_scientists/Clone__Predict_who_will_move_to_a_new_job.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Import data
Step 2. Visualization
Step 3. Check missing Value and Replace Them with average of columns
Step 4. Type Tansfer - Categorical to Numerical
Step 5. Modeling & Prediction
Step 6. Evaluation - AUC
```
---

<<<<<<< HEAD
**[2. Youtube trend Analysis : Check Daily statistics for trending Youtube videos](https://github.com/sw-song/TIA/blob/main/2_Youtube_trend_Analysis/youtube_trend_analysis.ipynb)**
=======
**[2. Youtube trend Analysis : Check Daily statistics for trending Youtube videos](https://github.com/sw-song/TIA/blob/main/Youtube_trend_KR/youtube_trend_analysis.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Data Load & EDA
Step 2. Correlation Check - Heatmap
(+Time Series)
Step 3. Visualization - Numerical Columns
Step 4. Visualization - WordCloud
Step 5. Machine Learning Modeling(Keras)
```
---

<<<<<<< HEAD
**[3. NLP with Disaster Tweets - Clone Project(Kaggle, NLP Getting Started Tutorial, Phill Culliton)](https://github.com/sw-song/TIA/blob/main/3_NLP_with_Disaster_Tweets/Clone_NLP_Getting_Started_Tutorial.ipynb)**
=======
**[3. NLP Getting Started Tutorial - Clone Project(Kaggle, NLP Getting Started Tutorial, Phill Culliton)](https://github.com/sw-song/TIA/blob/main/NLP_with_Disaster_Tweets/Clone_NLP_Getting_Started_Tutorial.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Data Load & EDA
Step 2. Text -> Vectorization(One Hot Encoding)
Step 3. Cross Validation Check
Step 4. Modeling
Step 5. Save / Submission(kaggle)
```
---

<<<<<<< HEAD
**[4. Telecom Users Dataset Analysis - Predict User's Next Action with Logistic Regression](https://github.com/sw-song/TIA/blob/main/4_Telecom_users_analysis/quick-start-eda-to-machine-learning-logistic.ipynb)**
=======
**[4. Telecom Users Dataset Analysis - Predict User's Next Action with Logistic Regression](https://github.com/sw-song/TIA/blob/main/Telecom_users_analysis/quick-start-eda-to-machine-learning-logistic.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Data Load & EDA
Step 2. Data Preprocessing
Step 3. Dataset Split(Train : Test = 0.8 : 0.2)
Step 4. Modeling : Logistic Regression
```

<<<<<<< HEAD
**[4+. Telecom Users Dataset Analysis - Clone Project(Kaggle, EDA and Building models for predicting outflow](https://github.com/sw-song/TIA/blob/main/4_Telecom_users_analysis/Clone_EDA_and_Building_models_for_predicting_outflow.ipynb)**
=======
**[4+. Telecom Users Dataset Analysis - Clone Project(Kaggle, EDA and Building models for predicting outflow](https://github.com/sw-song/TIA/blob/main/Telecom_users_analysis/Clone_EDA_and_Building_models_for_predicting_outflow.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Data Description
Step 2. Dependency research and formulation of hypothesis
Step 3. Building models to predict outflow
```
---

<<<<<<< HEAD
**[5. Heart Attack Analysis and Prediction - Binary Classification with Logistic Regression](https://github.com/sw-song/TIA/blob/main/5_Heart_Attack_Analysis_and_Prediction/quick-start-Binary_Classification_with_Logistic_Regression.ipynb)**
=======
**[5. Heart Attack Analysis and Prediction - Binary Classification with Logistic Regression](https://github.com/sw-song/TIA/blob/main/Heart_Attack_Analysis_and_Prediction/quick-start-Binary_Classification_with_Logistic_Regression.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Data Description
Step 2. EDA
Step 3. Correlation Check
Step 4. Test Data Split and Standard Scaling (Test size = 0.3)
Step 5. Modeling and Prediction
```

<<<<<<< HEAD
**[5+. Heart Attack Analysis and Prediction - Clone Project(Kaggle, Heart Attack Prediction_95.4% accuracy)](https://github.com/sw-song/TIA/blob/main/5_Heart_Attack_Analysis_and_Prediction/Clone_Heart_attack_prediction.ipynb)**
=======
**[5+. Heart Attack Analysis and Prediction - Clone Project(Kaggle, Heart Attack Prediction_95.4% accuracy)](https://github.com/sw-song/TIA/blob/main/Heart_Attack_Analysis_and_Prediction/Clone_Heart_attack_prediction.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Data Description - missingno
Step 2. EDA - pandas_profiling
Step 3. Data preprocessing - remove Outlier, upsampling
Step 4. modeling / prediction / evaluation
Step 5. check feature importance
```
---

<<<<<<< HEAD
**[6. Bankruptcy Prediction with KNN - Acc 97%](https://github.com/sw-song/TIA/blob/main/6_Company_Bankruptcy_Prediction/Bankruptcy_Prediction_with_KNN.ipynb)**
=======
**[6. Bankruptcy Prediction with KNN - Acc 97%](https://github.com/sw-song/TIA/blob/main/Company_Bankruptcy_Prediction/Bankruptcy_Prediction_with_KNN.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Data Description
Step 2. Data Preprocessing - MinMaxScaling
Step 3. Machine Learning Modeling & Prediction
```

<<<<<<< HEAD
**[6+. Bankruptcy_Prediction - Clone Project(Simple, yet, Powerful Bankrupt Prediction Model)](https://github.com/sw-song/TIA/blob/main/6_Company_Bankruptcy_Prediction/Clone_Powerful_Bankrupt_Prediction.ipynb)**
=======
**[6+. Bankruptcy_Prediction - Clone Project(Simple, yet, Powerful Bankrupt Prediction Model)](https://github.com/sw-song/TIA/blob/main/Company_Bankruptcy_Prediction/Clone_Powerful_Bankrupt_Prediction.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Data Loading and Data Cleaning
Step 2. Model Based Feature Selection
Step 3. Descriptive Analysis
Step 4. Data Analysis
Step 5. Predicting bankruptcy
Step 6. Conclusions
```
---
<<<<<<< HEAD
**[7. Anomaly Detection with XGB Classifier(base model Accuracy 79%) - Facebook Recruiting IV: Human or Robot?](https://github.com/sw-song/TIA/blob/main/7_Classification_Human_or_Robot/Anomaly_Detection_with_XGBClassifier.ipynb)**
=======
**[7. Anomaly Detection with XGB Classifier(base model Accuracy 79%) - Facebook Recruiting IV: Human or Robot?](https://github.com/sw-song/TIA/blob/main/Classification_Human_or_Robot/Anomaly_Detection_with_XGBClassifier.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Data load & EDA
Step 2. Preprocessing - replace all values with count number
Step 3. Preprocessing - Upsampling
Step 4. Train / Valid Set Split
Step 5. Modeling
Step 6. Prediction
```

---
<<<<<<< HEAD
**[8. Stroke Prediction with EASY Ensemble - Acc 90%(Random Forest Base model - 90%, Gradient Boosting Tuning Model)](https://github.com/sw-song/TIA/blob/main/8_Stroke_Prediction/stroke_prediction.ipynb)**
=======
**[8. Stroke Prediction with EASY Ensemble - Acc 90%(Random Forest Base model - 90%, Gradient Boosting Tuning Model)](https://github.com/sw-song/TIA/blob/main/Stroke_Prediction/stroke_prediction.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Data Load & EDA
Step 2. Feature Engineering
     2-a. Binary Features
     2-b. Continuous Features
     2-c. Categorical Features
Step 3. Train / Test set Split & Upsampling
Step 4. Modeling & Prediction
```

<<<<<<< HEAD
**[8+. Stroke Prediction - Clone Project(Stroke Prediction Beginner's Guide)](https://github.com/sw-song/TIA/blob/main/8_Stroke_Prediction/Clone_stroke_prediction.ipynb)**
=======
**[8+. Stroke Prediction - Clone Project(Stroke Prediction Beginner's Guide)](https://github.com/sw-song/TIA/blob/main/Stroke_Prediction/Clone_stroke_prediction.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Importing the necessary libraries
Step 2. Importing the Data using Pandas read_csv(). And calling head() and info() on the DataFrame
Step 3. Preprocessing Data before Exploratory Data Analysis
Step 4. Exploratory Data Analysis on Stroke Prediction Data
Step 5. Preparing the Data for Prediction
Step 6. Creating a Model for Stroke Prediction
```

---
<<<<<<< HEAD
**[9. Predict Students Performance with MultiOutputRegressor - R2(training set) 45%](https://github.com/sw-song/TIA/blob/main/9_Students_Performance_in_Exams/Predict_Students_Performance.ipynb)**
=======
**[9. Predict Students Performance with MultiOutputRegressor - R2(training set) 45%](https://github.com/sw-song/TIA/blob/main/Students_Performance_in_Exams/Predict_Students_Performance.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Data Load & EDA
Step 2. Visualization
     2-a. Each X's distribution
     2-b. Each y's distribution
     2-c. 'X & y's distribution
Step 3. Data Preprocessing
Step 4. Modeling & Prediction
```

<<<<<<< HEAD
**[9+. Students Performance in Exams - Clone Project(Data Science Notes 4: Machine Learning(ML))](https://github.com/sw-song/TIA/blob/main/9_Students_Performance_in_Exams/Clone_Data_Science_Notes_4.ipynb)**
=======
**[9+. Students Performance in Exams - Clone Project(Data Science Notes 4: Machine Learning(ML))](https://github.com/sw-song/TIA/blob/main/Students_Performance_in_Exams/Clone_Data_Science_Notes_4.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Imports and Datasets
Step 2. Regression
     2-a. Linear Regression 
     2-b. Decision Tree Regressor
     2-c. Random Forest Regressor
Step 3. Classification
     3-a. Preparing Data
     3-b. One-Hot Encoding
     3-c. Logistic Regression
     3-d. KNN
     3-e. SVM
     3-f. GaussianNB
     3-g. Decision Tree
     3-h. Random Forest
     3-i. Perceptron
     3-j. Stochastic Gradient Descent (SGD)
     3-k. Ridge Regression
Step 4. Conclusion
```
---
<<<<<<< HEAD
**[10. Breast Cancer Prediction - 3 types(Basic, MinMaxScaled, StandardScaled) of comparison](https://github.com/sw-song/TIA/blob/main/10_Breast_Cancer_Wisconsin/Breast_Cancer_Prediction__with_3type_of_Data.ipynb)**
=======
**[10. Breast Cancer Prediction - 3 types(Basic, MinMaxScaled, StandardScaled) of comparison](https://github.com/sw-song/TIA/blob/main/Breast_Cancer_Wisconsin/Breast_Cancer_Prediction__with_3type_of_Data.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Data Load & EDA & Preprocessing
Step 2. Visualization
     2-a. Correlation Heatmap - raw data
     2-b. Correlation Heatmap - MinMaxScaled data
     2-c. Correlation Heatmap - StandardScaled data
Step 3. Modeling & Prediction
     3-a. Logistic Regression - raw data
     3-b. SGDClassifier       - raw data
     3-c. Logistic Regression - MinMaxScaled data
     3-d. SGDClassifier       - MinMaxScaled data
     3-e. Logistic Regression - StandardScaled data
     3-f. SGDClassifier       - StandardScaled data
Step 4. Conclusion
```

<<<<<<< HEAD
**[10+. Breast Cancer Prediction - Clone Project(Feature Selection and Data Visualization)](https://github.com/sw-song/TIA/blob/main/10_Breast_Cancer_Wisconsin/Clone_Feature_Selection_and_Data_Visualization.ipynb)**
=======
**[10+. Breast Cancer Prediction - Clone Project(Feature Selection and Data Visualization)](https://github.com/sw-song/TIA/blob/main/Breast_Cancer_Wisconsin/Clone_Feature_Selection_and_Data_Visualization.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 1. Data Analysis
Step 2. Data Visualization
     2-a. violinplot
     2-b. boxplot
     2-c. jointplot
     2-d. pairgrid
     2-e. swarmplot
     2-f. heatmap
Step 3. Feature Selection and Random Forest Classification
     3-a. Feature selection with correlation and random forest classification
     3-b. Univariate feature selection and random forest classification
     3-c. Recursive feature elimination (RFE) with random forest
     3-d. Recursive feature elimination with cross validation (RFECV) and random forest classification
     3-e. Tree based feature selection and random forest classification
Step 4. Feature Extraction
Conclusion
```
<<<<<<< HEAD
---
**[11. Quick Start - Simple NN Basic Model with Fasion MNIST](https://github.com/sw-song/TIA/blob/main/11_Fashion_mnist_classification/fasion_mnist_basic.ipynb)**
=======

**[11. Quick Start - Simple NN Basic Model with Fasion MNIST](https://github.com/sw-song/TIA/blob/main/Fashion_mnist_classification/fasion_mnist_basic.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 0. Library Import
Step 1. Dataset Load and EDA
Step 2. Data Preprocessing
Step 3. Modeling
Step 4. Model Compile
Step 5. Checkpoint
Step 6. Model Fit
Step 7. Model Evaluate
```
<<<<<<< HEAD
---
**[12. Quick Start - Simple NN Basic Model with iris dataset](https://github.com/sw-song/TIA/blob/main/12_iris_classification/iris_basic.ipynb)**
=======


**[12. Quick Start - Simple NN Basic Model with iris dataset](https://github.com/sw-song/TIA/blob/main/iris_classification/iris_basic.ipynb)**
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```
Step 0. Library Import
Step 1. Dataset Load
Step 2. Data Preprocessing
Step 3. Modeling
Step 4. Model Compile
Step 5. Checkpoint
Step 6. Model Fit
Step 7. Model Evaluate
<<<<<<< HEAD
```
---
**[13. Quick Start - Simple CNN Model with RPS dataset](https://github.com/sw-song/TIA/blob/main/13_RPS_Image_Classification/RPS_basic_cnn.ipynb)**
```
Step 0. Library Import
Step 1. Dataset Load
Step 2. Data Generator
Step 3. Modeling
Step 4. Model Compile
Step 5. Save Model Checkpoint
Step 6. Model Fit
Step 7. Model Evaluate & Save
Step 8. Reload Model
=======
>>>>>>> ebd5085393bf39c32a163c0fdbfb388fbd4d8975
```